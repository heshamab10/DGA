{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSDwqjupgwv6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl2_COafpKgx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read xlsx file using pandas\n",
        "\n",
        "data = pd.read_excel(r\"/content/drive/MyDrive/Actual.xlsx\")\n"
      ],
      "metadata": {
        "id": "BGb0hpx8jg4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMkcsf0hrFYA",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts = data['actual Data'].value_counts()\n",
        "print(class_counts)"
      ],
      "metadata": {
        "id": "0llJny-QjwpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "value_counts = data['actual Data'].value_counts()\n",
        "\n",
        "# Get the maximum count (for class 7)\n",
        "max_count = value_counts.max()\n",
        "\n",
        "upsampled_dfs = {}\n",
        "\n",
        "# Iterate over each class\n",
        "for class_label, count in value_counts.items():\n",
        "    # Skip class 7 since we don't want to upsample it\n",
        "    if class_label == 7:\n",
        "        continue\n",
        "\n",
        "    # Get the DataFrame for the current class\n",
        "    class_df = data[data['actual Data'] == class_label]\n",
        "\n",
        "    # Upsample the current class to match the maximum count\n",
        "    upsampled_df = resample(class_df,\n",
        "                            replace=True,\n",
        "                            n_samples=max_count,\n",
        "                            random_state=42)\n",
        "\n",
        "    # Store the upsampled DataFrame in the dictionary\n",
        "    upsampled_dfs[class_label] = upsampled_df\n",
        "\n",
        "# Combine the upsampled DataFrames and the original DataFrame for class 7\n",
        "upsampled_df_list = list(upsampled_dfs.values()) + [data[data['actual Data'] == 7]]\n",
        "\n",
        "# Concatenate all the upsampled DataFrames\n",
        "upsampled_df = pd.concat(upsampled_df_list, ignore_index=True)"
      ],
      "metadata": {
        "id": "rYrvqAiFkBJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(upsampled_df['actual Data'].value_counts())"
      ],
      "metadata": {
        "id": "loa10ufpolKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6Jtbt9krHdy"
      },
      "outputs": [],
      "source": [
        "upsampled_df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnaEzsyGrUO8"
      },
      "outputs": [],
      "source": [
        "upsampled_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols = upsampled_df.select_dtypes(include=['float64', 'int64']).columns\n",
        "\n",
        "# Plot a box plot for each numeric feature\n",
        "fig, axes = plt.subplots(nrows=len(numeric_cols), ncols=1, figsize=(10, len(numeric_cols) * 4))\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    ax = axes[i] if len(numeric_cols) > 1 else axes\n",
        "    sns.boxplot(data=upsampled_df, x=upsampled_df[col], ax=ax)\n",
        "    ax.set_title(f'Box Plot for {col}')\n",
        "    ax.set_ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Handle outliers and skewed distributions\n",
        "from scipy import stats\n",
        "\n",
        "for col in numeric_cols:\n",
        "    # Check for outliers\n",
        "    q1 = upsampled_df[col].quantile(0.25)\n",
        "    q3 = upsampled_df[col].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    outlier_lower = q1 - 1.5 * iqr\n",
        "    outlier_upper = q3 + 1.5 * iqr\n",
        "    upsampled_df[col] = upsampled_df[col].clip(outlier_lower, outlier_upper)\n",
        "\n",
        "    # Check for skewness and apply log transformation if needed\n",
        "    skewness = stats.skew(upsampled_df[col])\n",
        "    if abs(skewness) > 0.5:\n",
        "        upsampled_df[col] = np.log1p(upsampled_df[col])"
      ],
      "metadata": {
        "id": "dCK9xw70q0wV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(nrows=len(numeric_cols), ncols=1, figsize=(10, len(numeric_cols) * 4))\n",
        "\n",
        "for i, col in enumerate(numeric_cols):\n",
        "    ax = axes[i] if len(numeric_cols) > 1 else axes\n",
        "    sns.boxplot(data=upsampled_df, x=upsampled_df[col], ax=ax)\n",
        "    ax.set_title(f'Box Plot for {col}')\n",
        "    ax.set_ylabel(col)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bN6Jy_virQK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(upsampled_df['actual Data'].value_counts())"
      ],
      "metadata": {
        "id": "ZqZePJrxrU7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upsampled_df.describe().T"
      ],
      "metadata": {
        "id": "IsGjJ8cdrhoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg6elbdKuCgn"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Split data into features and target\n",
        "X = upsampled_df.drop('actual Data', axis=1)\n",
        "y = upsampled_df['actual Data']\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Encode the target column\n",
        "encoder = LabelEncoder()\n",
        "y_train_encoded = encoder.fit_transform(y_train)\n",
        "y_test_encoded = encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fdkka2h5yX6I"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define the number of input features\n",
        "num_features = X_train_scaled.shape[1]\n",
        "\n",
        "# Define the number of classes\n",
        "num_classes = len(encoder.classes_)\n",
        "\n",
        "# Define the neural network architecture\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(num_features,)),\n",
        "    keras.layers.Dense(32, activation='relu'),\n",
        "    keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train_scaled, y_train_encoded,\n",
        "                    batch_size=32,\n",
        "                    epochs=100,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZV7KTG8koGj"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "plt.plot(epochs, acc, 'y', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "# Define the transformers\n",
        "scaler = StandardScaler()\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Create the pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', scaler),\n",
        "])\n",
        "\n",
        "# Fit the pipeline on your training data\n",
        "pipeline.fit(X_train)\n",
        "\n",
        "# For inference, use the pipeline to transform the input data\n",
        "def predict(input_data):\n",
        "    # Assuming input_data is a list or numpy array of length 5\n",
        "    transformed_data = pipeline.transform(input_data)\n",
        "    prediction = model.predict(transformed_data)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "cDe6yPx-MRm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the values of the next array for inference\n",
        "x_sample = np.array([   376, 575, 146, 1092 ,146   ]).reshape(1, -1)\n",
        "\n",
        "# Make a prediction on the sample\n",
        "y_pred = predict(x_sample)\n",
        "\n",
        "# Get the predicted class label\n",
        "predicted_class = np.argmax(y_pred, axis=1)[0]\n",
        "\n",
        "# Print the prediction\n",
        "print(f\"Predicted label: {encoder.inverse_transform([predicted_class])[0]}\")\n",
        "\n",
        "# Print the predicted probabilities for all classes\n",
        "print(\"\\nPredicted probabilities:\")\n",
        "for i, prob in enumerate(y_pred[0]):\n",
        "    print(f\"Class {encoder.inverse_transform([i])[0]}: {prob * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "v90fMyi1u3MV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}